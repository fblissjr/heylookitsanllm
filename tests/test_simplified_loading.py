#!/usr/bin/env python3
"""
Test script to verify simplified MLX VLM loading works correctly
"""

import sys
import os
import logging
from pathlib import Path

# Add src to path
current_dir = Path(__file__).parent
src_dir = current_dir / "src"
sys.path.insert(0, str(src_dir))

def test_simplified_loading():
    """Test that simplified MLX VLM loading works correctly"""
    
    # Set up logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("ğŸ§ª Testing simplified MLX VLM loading...")
    
    try:
        # Test direct MLX VLM loading
        from mlx_vlm.utils import load as vlm_load
        
        # Try to load the gemma3n model that was failing before
        model_path = "modelzoo/google/gemma-3n-E4B-it-bf16-mlx"
        
        print(f"ğŸ“ Testing model path: {model_path}")
        
        if not Path(model_path).exists():
            print("âš ï¸  Model path does not exist - skipping actual loading test")
            print("âœ… Import test passed - MLX VLM loading should work")
            return True
        
        print("ğŸ”„ Loading model with direct MLX VLM...")
        model, processor = vlm_load(model_path)
        
        print("âœ… Model loaded successfully!")
        print(f"ğŸ“Š Model type: {type(model)}")
        print(f"ğŸ“Š Processor type: {type(processor)}")
        
        # Test a simple generation
        try:
            from mlx_vlm.prompt_utils import apply_chat_template
            
            messages = [{"role": "user", "content": "Hello"}]
            prompt = apply_chat_template(processor, model.config, messages, num_images=0)
            
            print("âœ… Chat template application worked!")
            print(f"ğŸ“ Generated prompt: {prompt[:100]}...")
            
        except Exception as e:
            print(f"âš ï¸  Chat template test failed: {e}")
            # This is okay - we just wanted to test model loading
        
        return True
        
    except Exception as e:
        print(f"âŒ Simplified loading test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_ollama_api():
    """Test that Ollama API translation works with simplified loading"""
    
    print("\nğŸ§ª Testing Ollama API integration...")
    
    try:
        # Test that we can import and instantiate the simplified provider
        from heylook_llm.providers.mlx_provider_optimized import MLXProvider
        
        # Test config for gemma3n model
        config = {
            "model_path": "modelzoo/google/gemma-3n-E4B-it-bf16-mlx",
            "vision": True,
            "temperature": 0.8,
            "top_p": 0.95,
            "max_tokens": 100
        }
        
        provider = MLXProvider("gemma3n-e4b-it", config, verbose=True)
        
        print("âœ… MLX Provider instantiated successfully!")
        print("ğŸ“Š Provider configured for vision model")
        
        # Test that the translation logic works
        from heylook_llm.middleware.ollama import OllamaTranslator
        
        translator = OllamaTranslator()
        
        # Test Ollama chat request translation
        ollama_request = {
            "model": "gemma3n-e4b-it",
            "messages": [
                {"role": "user", "content": "Hello"}
            ]
        }
        
        openai_request = translator.translate_ollama_chat_to_openai(ollama_request)
        
        print("âœ… Ollama request translation worked!")
        print(f"ğŸ“ OpenAI request: {openai_request}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ollama API test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run all tests"""
    
    print("ğŸš€ Simplified MLX VLM Loading - Test Suite")
    print("=" * 50)
    
    tests = [
        ("Simplified Loading", test_simplified_loading),
        ("Ollama API Integration", test_ollama_api)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"ğŸ§ª {test_name}")
        print("="*50)
        
        try:
            result = test_func()
            results.append(result)
        except Exception as e:
            print(f"âŒ Test crashed: {e}")
            results.append(False)
    
    # Summary
    print("\n" + "="*50)
    print("ğŸ“Š TEST SUMMARY")
    print("="*50)
    
    passed = sum(results)
    total = len(results)
    
    print(f"âœ… Tests passed: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ All tests passed!")
        print("âœ¨ Simplified MLX VLM loading is ready!")
        print("\nğŸš€ Next steps:")
        print("  1. Start server: heylookllm --host 0.0.0.0 --log-level DEBUG")
        print("  2. Test Ollama API: python tests/test_ollama.py")
        return 0
    else:
        print("âš ï¸  Some tests failed - check the logs above")
        return 1

if __name__ == "__main__":
    sys.exit(main())
